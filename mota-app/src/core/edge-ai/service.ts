/**
 * ç«¯ä¾§AIæœåŠ¡å®ç°
 */

import http from '../http/request';
import {
  ModelType,
  ModelStatus,
  type ModelInfo,
  type InferenceRequest,
  type InferenceResult,
  type DownloadProgress,
  type ModelConfig,
  type PerformanceStats
} from './types';

/**
 * ç«¯ä¾§AIæœåŠ¡ç±»
 */
class EdgeAIService {
  private readonly baseUrl = '/api/edge-ai';
  private readonly storageKey = 'edge_ai_config';
  private models: Map<string, ModelInfo> = new Map();
  private downloadCallbacks: Map<string, (progress: DownloadProgress) => void> = new Map();

  /**
   * è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
   */
  async getAvailableModels(): Promise<ModelInfo[]> {
    const models = await http.get<ModelInfo[]>(`${this.baseUrl}/models`);
    models.forEach(model => this.models.set(model.id, model));
    return models;
  }

  /**
   * è·å–æ¨¡å‹ä¿¡æ¯
   */
  async getModelInfo(modelId: string): Promise<ModelInfo> {
    if (this.models.has(modelId)) {
      return this.models.get(modelId)!;
    }
    const model = await http.get<ModelInfo>(`${this.baseUrl}/models/${modelId}`);
    this.models.set(modelId, model);
    return model;
  }

  /**
   * ä¸‹è½½æ¨¡å‹
   */
  async downloadModel(
    modelId: string,
    onProgress?: (progress: DownloadProgress) => void
  ): Promise<void> {
    if (onProgress) {
      this.downloadCallbacks.set(modelId, onProgress);
    }

    try {
      // æ›´æ–°æ¨¡å‹çŠ¶æ€
      const model = await this.getModelInfo(modelId);
      model.status = ModelStatus.DOWNLOADING;
      this.models.set(modelId, model);

      // æ¨¡æ‹Ÿä¸‹è½½è¿›åº¦ï¼ˆå®é™…åº”è¯¥é€šè¿‡WebSocketæˆ–è½®è¯¢è·å–ï¼‰
      await this.simulateDownload(modelId, model.size, onProgress);

      // ä¸‹è½½å®Œæˆ
      model.status = ModelStatus.DOWNLOADED;
      model.progress = 100;
      this.models.set(modelId, model);

      // ä¿å­˜åˆ°æœ¬åœ°
      await this.saveModelToLocal(modelId);
    } catch (error) {
      const model = this.models.get(modelId);
      if (model) {
        model.status = ModelStatus.ERROR;
        this.models.set(modelId, model);
      }
      throw error;
    } finally {
      this.downloadCallbacks.delete(modelId);
    }
  }

  /**
   * æ¨¡æ‹Ÿä¸‹è½½è¿›åº¦
   */
  private async simulateDownload(
    modelId: string,
    totalSize: number,
    onProgress?: (progress: DownloadProgress) => void
  ): Promise<void> {
    const chunks = 20;
    const chunkSize = totalSize / chunks;
    
    for (let i = 0; i <= chunks; i++) {
      await new Promise(resolve => setTimeout(resolve, 100));
      
      const downloaded = Math.min(i * chunkSize, totalSize);
      const progress: DownloadProgress = {
        modelId,
        downloaded,
        total: totalSize,
        progress: (downloaded / totalSize) * 100,
        speed: chunkSize * 10 // æ¨¡æ‹Ÿé€Ÿåº¦
      };
      
      if (onProgress) {
        onProgress(progress);
      }
      
      // æ›´æ–°æ¨¡å‹è¿›åº¦
      const model = this.models.get(modelId);
      if (model) {
        model.progress = progress.progress;
        this.models.set(modelId, model);
      }
    }
  }

  /**
   * ä¿å­˜æ¨¡å‹åˆ°æœ¬åœ°
   */
  private async saveModelToLocal(modelId: string): Promise<void> {
    try {
      const localModels = this.getLocalModels();
      if (!localModels.includes(modelId)) {
        localModels.push(modelId);
        uni.setStorageSync('local_models', JSON.stringify(localModels));
      }
    } catch (error) {
      console.error('ä¿å­˜æ¨¡å‹å¤±è´¥:', error);
    }
  }

  /**
   * è·å–æœ¬åœ°æ¨¡å‹åˆ—è¡¨
   */
  private getLocalModels(): string[] {
    try {
      const data = uni.getStorageSync('local_models');
      return data ? JSON.parse(data) : [];
    } catch (error) {
      return [];
    }
  }

  /**
   * åˆ é™¤æ¨¡å‹
   */
  async deleteModel(modelId: string): Promise<void> {
    try {
      const localModels = this.getLocalModels();
      const filtered = localModels.filter(id => id !== modelId);
      uni.setStorageSync('local_models', JSON.stringify(filtered));
      
      const model = this.models.get(modelId);
      if (model) {
        model.status = ModelStatus.NOT_DOWNLOADED;
        model.progress = 0;
        this.models.set(modelId, model);
      }
    } catch (error) {
      console.error('åˆ é™¤æ¨¡å‹å¤±è´¥:', error);
      throw error;
    }
  }

  /**
   * åŠ è½½æ¨¡å‹
   */
  async loadModel(modelId: string): Promise<void> {
    const model = await this.getModelInfo(modelId);
    
    if (model.status !== ModelStatus.DOWNLOADED) {
      throw new Error('æ¨¡å‹æœªä¸‹è½½');
    }
    
    // æ¨¡æ‹ŸåŠ è½½è¿‡ç¨‹
    await new Promise(resolve => setTimeout(resolve, 500));
    
    model.status = ModelStatus.LOADED;
    this.models.set(modelId, model);
  }

  /**
   * å¸è½½æ¨¡å‹
   */
  async unloadModel(modelId: string): Promise<void> {
    const model = this.models.get(modelId);
    if (model && model.status === ModelStatus.LOADED) {
      model.status = ModelStatus.DOWNLOADED;
      this.models.set(modelId, model);
    }
  }

  /**
   * æ‰§è¡Œæ¨ç†
   */
  async inference(request: InferenceRequest): Promise<InferenceResult> {
    const model = this.models.get(request.modelId);
    
    if (!model) {
      throw new Error('æ¨¡å‹ä¸å­˜åœ¨');
    }
    
    if (model.status !== ModelStatus.LOADED) {
      // è‡ªåŠ¨åŠ è½½æ¨¡å‹
      await this.loadModel(request.modelId);
    }
    
    // è°ƒç”¨åç«¯APIè¿›è¡Œæ¨ç†
    const startTime = Date.now();
    const result = await http.post<InferenceResult>(`${this.baseUrl}/inference`, request);
    result.duration = Date.now() - startTime;
    
    return result;
  }

  /**
   * è·å–é…ç½®
   */
  getConfig(): ModelConfig {
    try {
      const data = uni.getStorageSync(this.storageKey);
      return data ? JSON.parse(data) : this.getDefaultConfig();
    } catch (error) {
      return this.getDefaultConfig();
    }
  }

  /**
   * æ›´æ–°é…ç½®
   */
  updateConfig(config: Partial<ModelConfig>): void {
    const current = this.getConfig();
    const updated = { ...current, ...config };
    uni.setStorageSync(this.storageKey, JSON.stringify(updated));
  }

  /**
   * è·å–é»˜è®¤é…ç½®
   */
  private getDefaultConfig(): ModelConfig {
    return {
      enabled: true,
      autoDownload: false,
      wifiOnly: true,
      maxCacheSize: 500 * 1024 * 1024 // 500MB
    };
  }

  /**
   * è·å–æ€§èƒ½ç»Ÿè®¡
   */
  async getPerformanceStats(modelId: string): Promise<PerformanceStats> {
    return await http.get<PerformanceStats>(`${this.baseUrl}/stats/${modelId}`);
  }

  /**
   * æ¸…ç†ç¼“å­˜
   */
  async clearCache(): Promise<void> {
    try {
      uni.removeStorageSync('local_models');
      this.models.forEach(model => {
        if (model.status !== ModelStatus.NOT_DOWNLOADED) {
          model.status = ModelStatus.NOT_DOWNLOADED;
          model.progress = 0;
        }
      });
    } catch (error) {
      console.error('æ¸…ç†ç¼“å­˜å¤±è´¥:', error);
      throw error;
    }
  }

  /**
   * è·å–ç¼“å­˜å¤§å°
   */
  getCacheSize(): number {
    let totalSize = 0;
    const localModels = this.getLocalModels();
    
    localModels.forEach(modelId => {
      const model = this.models.get(modelId);
      if (model) {
        totalSize += model.size;
      }
    });
    
    return totalSize;
  }

  /**
   * æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
   */
  formatSize(bytes: number): string {
    if (bytes < 1024) return `${bytes}B`;
    if (bytes < 1024 * 1024) return `${(bytes / 1024).toFixed(1)}KB`;
    if (bytes < 1024 * 1024 * 1024) return `${(bytes / (1024 * 1024)).toFixed(1)}MB`;
    return `${(bytes / (1024 * 1024 * 1024)).toFixed(1)}GB`;
  }

  /**
   * è·å–æ¨¡å‹ç±»å‹åˆ—è¡¨
   */
  getModelTypes(): Array<{ value: ModelType; label: string; icon: string }> {
    return [
      { value: ModelType.TEXT_CLASSIFICATION, label: 'æ–‡æœ¬åˆ†ç±»', icon: 'ğŸ“' },
      { value: ModelType.SENTIMENT_ANALYSIS, label: 'æƒ…æ„Ÿåˆ†æ', icon: 'ğŸ˜Š' },
      { value: ModelType.KEYWORD_EXTRACTION, label: 'å…³é”®è¯æå–', icon: 'ğŸ”‘' },
      { value: ModelType.TEXT_SUMMARIZATION, label: 'æ–‡æœ¬æ‘˜è¦', icon: 'ğŸ“„' },
      { value: ModelType.IMAGE_CLASSIFICATION, label: 'å›¾åƒåˆ†ç±»', icon: 'ğŸ–¼ï¸' }
    ];
  }

  /**
   * è·å–çŠ¶æ€é¢œè‰²
   */
  getStatusColor(status: ModelStatus): string {
    const colors: Record<ModelStatus, string> = {
      [ModelStatus.NOT_DOWNLOADED]: '#999',
      [ModelStatus.DOWNLOADING]: '#3B82F6',
      [ModelStatus.DOWNLOADED]: '#10B981',
      [ModelStatus.LOADED]: '#10B981',
      [ModelStatus.ERROR]: '#EF4444'
    };
    return colors[status];
  }

  /**
   * è·å–çŠ¶æ€æ–‡æœ¬
   */
  getStatusText(status: ModelStatus): string {
    const texts: Record<ModelStatus, string> = {
      [ModelStatus.NOT_DOWNLOADED]: 'æœªä¸‹è½½',
      [ModelStatus.DOWNLOADING]: 'ä¸‹è½½ä¸­',
      [ModelStatus.DOWNLOADED]: 'å·²ä¸‹è½½',
      [ModelStatus.LOADED]: 'å·²åŠ è½½',
      [ModelStatus.ERROR]: 'é”™è¯¯'
    };
    return texts[status];
  }
}

// å¯¼å‡ºå•ä¾‹
export const edgeAIService = new EdgeAIService();